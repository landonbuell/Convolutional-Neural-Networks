% ================
% Landon Buell
% Prof. Yu
% Gradient Desent Notes
% 29 January 2020
% ================

\documentclass[12pt,letterpaper]{article}

\usepackage{graphicx}
\usepackage{multicol}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}

% ================================================================

\begin{document}

% ================================================================

\title{
\begin{Huge}
Training a Multilayer Neural Network \\
\end{Huge} 
\Large with Stochastic Gradient Descent}
\author{Landon Buell}
\date{27 January 2020}
\maketitle

% ================================================================

\section{Introduction}
\paragraph*{}Neural Networks are inspired from architecture of the human brain. With their first conception in the 1940's, these networks were designed to mimic patterns and processes that occur between neurons \cite{McCulloch}. However, instead of several billions of neurons, each connected to hundreds of thousands of other neurons, we tend to build neural networks that exist in discrete layers, connected through a series of consecutive linear transformations. This architecture for artificial neural networks is was proposed in the in 1950's and is often dubbed the \textit{multi-layer perceptron} model \cite{Geron}. 
\paragraph*{}In order to train this model to produce desired results, some algorithm needs to find a set of parameters of each linear transformation that achieves a desired result. In the case of mutli-layer neural network, the goal is to produce an appropriate set of entries in the network's final layer. We measure the validity of these entries with something called a \textit{cost} function, or \textit{error} function \cite{Goodfellow}. The way to minimize the output of this function to find a set of parameters within the model that achieves this minimal value. The algorithm that we will explore to find these set of parameters is called \textit{Stochastic Gradient Descent}.
\paragraph*{}Gradient Descent algorithms lie at the heart of several machine learning algorithms \cite{Goodfellow}. In general, the goal of the algorithm is find a set of parameters that minimize the value of a particular function, which we call the \textit{cost} or \textit{objective} function \cite{James}. To do this, we apply a procedure from multivariate calculus that repeats a set of steps until a local minimum of that particular function is found. Note that while we ideally want to find a global minimum (the minimum of the whole function), this is computationally unrealistic, so local minima of the function are often used in it's place. 
\paragraph*{}Suppose we have some scalar defined function, $f$ of $n$ independent variables. We can express this a function of $n$ entries or as a single vector of $n$ entries. We notate this as:
\begin{equation}
\label{f}
f = f(x_0,x_1,...,x_{n-2},x_{n-1}) = f(\vec{x})
\end{equation}
Althought the function is multivariate, it is still scalar-defined. The gradient of $f(\vec{x})$, returns a vector, with each element given by the partial derivative of $f$ with respect to the $i$-th variable:
\begin{equation}
\label{grad f}
\nabla \big[ f(x_0,x_1,...,x_{n-2},x_{n-1}) \big] =
\Big[ \frac{\partial f}{\partial x_0} , \frac{\partial f}{\partial x_1} , ... ,
\frac{\partial f}{\partial x_{n_2}} , \frac{\partial f}{\partial x_{n-1}} \Big]
\end{equation}
Geometrically, the gradient provides a vector that points in the direction that causes the value of $f$ to increase the fastest. In a two dimensional function, where the output is the 3rd dimension, this gives the direction of steepest ascent. Note that if the function of of $n$ variables, then this operation take place in $n$-dimensional vector space.
\paragraph*{}The general procedure of the Gradient Descent Algorithm is:
\begin{enumerate}
\item Pick a 'starting point', $p_0$ in the $n$-d space. This is done by  evaluating the function $f$ for each of it's $n$ input variables.
\item Compute the gradient of $f$, eq. (\ref{grad f}) at the point $p_0$. Multiply the gradient by $-1$. This is the direction of steepest \textit{descent}. 
\item Follow the negative gradient a certain distance, $\eta$ (called the \textit{learning rate}\cite{Geron}) to reach a new point $p_1$. 
\item Repeat steps 2 and 3 until the value of $-\nabla f$ returns 0 withina  certain tolerance. This indicates that a local minimum, or a saddle point has been found.
\end{enumerate}
The set of parameters at the final point $p_f$ are the set of parameters in each linear transformation that in general, minimize the value outputted by the objective function. 
\paragraph*{}Some gradient descent algorithms may repeat this whole procedure with a series of initial points, each time tracking the minimum and corresponding parameters. This way, each time the algorithm is repeated, a new minimum is attained, which allows for a greater chance to find a successively lower value. While it seems appealing at first thought, it is work noting that this whole algorithm as outlined is \textit{very} computationally expensive.
\paragraph*{}

% ================================================================

\section{Considerations and Conventions}

% ================================

\subsection{Structure}
\paragraph*{}It is important to understand the architecture of a multi-layer neural network (again, also called a \textit{multilayer perception} or MLP) at a very basic level. In it's simplest form as well will describe, a neural network is a collection of discrete layers of functions (often called \textit{neuron} or \textit{nodes}) \cite{Goodfellow}. The exact amount of layers in a network and the exact number of neurons in each layer depends on the type of task that the network seeks to accomplish. Currently, there is no formal rule to outline this, and is often determined on a emperical basis \cite{Geron}.
\paragraph*{}The entry point of a neural network, called \textit{Layer 0} is the set of functions (or values) that receives an initial piece of data. The number of these inputs neurons in this layer corresponds to the number of \textit{features} in the base data set. Thus if a sample of data has $n_0$ features, then there are $n_0$ neurons in this layer 0 of the neural network \cite{Geron}.
\paragraph*{}To move to the next layer, an operation is applied to all of the values in the previous layer. We model this linear transformation with standard matrix multiplication. Notation conventions for this will outlined in the next section. After each matrix multiplication is applied, the input is effectively transformed into the next layer of the network. It is important to know that although layer 0 has $n_0$ neurons, any other layer may have a different number of neurons in it, This difference is handled by the dimension of the matrix that allows for the transformation between adjacent layers.
\paragraph*{}In a network with $L$ layers, there are $L-1$ matrix multiplications required, the last one usually labeld $L-2$. (due to $0$ - indexing). Once the $L-2$ matrix has been applied to layer $L-2$, the resultant layer, $L-1$, is the output of the network, as it is the last layer. In the case of a network being used for a classification problem, the number of nodes in the final layer of the network, corresponds to the number of target classes \cite{Geron}. Thus if we built a \textit{K-Folds} classifier, the output layer of the CNN would have $n_{(l-1)} = K$ neurons.

% ================================

\subsection{Notation}
\paragraph*{}The mathematical description of neural networks and stochastic gradient descent (SGD) classifiers is largely based in linear algebra \cite{Goodfellow}. This means a great deal of matrix vector indexing is required to fully describe the procedure. For this work, I will be using a standard of $0$ - indexing all objects. I outline a notional convention for this work:
\begin{itemize}
\item A scalar is given by a lower case letter:
\begin{equation}
n_l
\end{equation} 
is the number of neurons (also called nodes or functions) in the 
$l$-th layer. 
\item A vector:
\begin{equation}
\vec{x}_{i}^{(l)}
\end{equation}
is the $i$-th entry in the vector $x$ in the $l$-th layer of a network. The vector that describes layer $l$ of the network has $n_l$ rows and 1 column. Thus the vector $\vec{x}^1$ has a $n_l$ number of components in it.
\item A matrix is given by an uppercase letter:
\begin{equation}
W_{i,j}^{{l}}
\end{equation}
is the entry in the $i$-th row, and the $j$-th column of matrix $W$ that operates on the $l$-th layer of a network. The matrix that operates on layer $l$ has $n_{(l+1)}$ rows and $n_{l}$ columns
\end{itemize}
\paragraph*{}Mathematically, each neuron contains a (floating point) number that can be operated on. 

% ================================================================

\section{Neural Network Procedure  - Feed Forward}
\paragraph*{}Suppose we have a linear neural network, with $L$ layers of neurons, each layer containing $n_l$ number of neurons in it. The first layer of neurons is called the \textit{input layer}, which contains $n_0$ neurons. This corresponds to the number of input features given to the network. The final layer of neurons is called the \textit{output layer} and corresponds to the number of target classes to place a sample into. Each sample input feature then fills in the entry of it's respective neuron. Thus, after presenting the network with an array of raw data, the $x^0$ vector then becomes:
\begin{equation}
\label{layer0}
\vec{x}^(0) = \big[ x^{(0)}_0 , x^{(0)}_1 , x^{(0)}_2 , ... , 
x^{(0)}_{n_0-2} , x^{(0)}_{n_0-1} \big]^T  
\end{equation} 
Understand that every entry in this vector is a numerical quantity.
\paragraph*{}To ease the computational complexity, most networks employ \textit{activation functions} \cite{Goodfellow} in order to scale the entries in each matrix and vector element. Different types of activation functions are used depending on the type of problem that the network is trained on. 

% ================================

\subsection{Forward Propagation}
\paragraph*{}The network must take this information in the form of a column vector and pass the information through itself. It must take the vector $\vec{x}^{(0)}$ representing the input layer and transform it to into the vector $\vec{x}^{(1)}$ representing the first hidden layer. This vector contrains all of the numerical values, called \textit{activations} \cite{Geron} for all of the neurons in that layer. 
\paragraph*{}This transformation between layers is mathematically given by a standard matrix-vector product. The weighting matrix $W^{(0)}$ operates on vector $\vec{x}^{(0)}$ to produce the entries in the vector $\vec{x}^{(1)}$. More generally, matrix $W^{(l)}$ operates on layer/vector $x^{(l)}$ to produce layer/vector $x^{(l+1)}$. Mathematically:
\begin{equation}
\label{feed forward}
\vec{x}^{(l+1)} = W^{(l)} \vec{x}^{(l)}
\end{equation}
The dimensions of matrix $W^{(l)}$ must then be $n_{l+1}$ rows by $n_l$ columns. This process of matrix multiplication makes up the bulk of the \textit{feed-forward} algorithm for neural networks. In a network with $L$ layers, there are $L$ vectors ($0$ through $L-1$) and $L-1$ weighting matrices ($0$ through $L-2$). Thus the final output output of a $L$-layer perception is given by:
\begin{equation}
\label{feed forward 2}
\vec{x}^{(L-1)} = W^{(L-2)} W^{(L-3)} \hdots W^{(1)} W^{(0)} \vec{x}^{(0)}
\end{equation}
Once the vector $\vec{x}^{(L-1)}$ is produced, the network has finished it's forward pass algorithm and a final output has been produced. 

% ================================

\subsection{The Weighting Matrices}
\paragraph*{}The actual procedure of this type of neural network is essentially this basic recursive linear algebra problem. It then raises the questions, how is each matrix, $W^{(l)}$ built? What are it's elements and what do they do? If we examine the matrix-vector equation (\ref{feed forward}), we can break this down further into it's constituent parts.
\paragraph*{}For simplification of superscripts and subscripts, let the layer, $\vec{x}^{(l+1)}$ be notated by the vector $\vec{y}$. This layer will contain $n_{l+1} = a$ neurons within it. Similarly, let the layer, $\vec{x}^{(l)}$ be the vector $\vec{x}$ with $n_l = b$ neurons in it. Thus the matrix $W^{(l)}$ has $a$ rows, and $b$ columns. Each entry is denoted as $W_{i,j}$ for the $i$-th row and the $j$-th column. The matrix-vector equation expanded out then becomes:
\begin{equation}
\label{mat-vec feed}
\begin{bmatrix}
y_0 \\ y_1 \\ \vdots \\ y_{a-2} \\ y_{a-1}
\end{bmatrix} =
\begin{bmatrix}
W_{0,0} & W_{0,1} & \hdots & W_{0,b-2} & W_{0,b-1} \\
W_{1,0} & W_{1,1} & \hdots & W_{1,b-2} & W_{1,b-1} \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
W_{a-2,0} & W_{a-2,1} & \hdots & W_{a-2,b-2} & W_{a-2,b-1} \\
W_{a-1,0} & W_{a-1,1} & \hdots & W_{a-1,b-2} & W_{a-1,b-1} \\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_1 \\ \vdots \\ x_{b-2} \\ x_{b-1}
\end{bmatrix}
\end{equation}
Keep in mind that $a$ may not be equal to $b$. We can now use this to understand a little bit more specifically what the weighting matrix is doing, and what each entry in the operation does.
\paragraph*{}From linear algebra, the entry $y_i$ in the column vector $y$ is given by the dot product between the $W_i$ row and the column vector $x$. We can denote this as:
\begin{equation}
\label{dot prod}
y_i = \sum_{j=0}^{b-1} W_{i,j}(x_j) = 
(W_{i,0}x_0) + (W_{i,1}x_1) +  ... + 
(W_{i,b-2}x_{b-2}) + (W_{i,b-1}x_{b-1})
\end{equation}
\paragraph*{}This equation tells us exactly how the elements in the layer $x$ influence the elements produced in layer $y$. Thus we can see that it is a linear combination of all elements in the layer $x$, whose coefficient are given by the corresponding entries in the weighting matrix that produces the elements in the next layer. For example, neuron $y_m$ is related to neuron $x_n$ by a factor of $W_{n,m}$. If the element $W_{m,n}$ is very small or zero, then $x_n$ has little or no affect on $y_m$. Conversely, if $W_{m,n}$ is very large, then changes in the value of $x_n$ have a large impact on $y_m$.
\paragraph*{}It is the structure, elements, and organization of these weighting matrices, $W^{(l)}$ that determine how the network behaves as a whole. For an untrained network, these elements are often pseudo-randomly generated (called a \textit{cold-start network}\cite{Geron}). With each training sample introduced to the model, we can use a training method such as stochastic gradient descent  to systematically adjust all elements in these $L-1$ weighting matrices. After enough samples, the model will have ideally converged on a set of elements in all matrices that allow for the production of a local or global minimum as defined by some cost function \cite{Goodfellow}. 

% ================================================================

\section{Neural Network Procedure - Back Propagation}
\paragraph*{}Suppose we have entered a single training data sample into a multi-layer neural network. Each input feature in layer $x^{(0)}$ is then transformed as prescribed above, until it reaches the output layer, $x^{(L-1)}$. The entries in each neuron in this layer correspond to the entries in a corresponding vector object of length $n_{L-1}$. We can now compare this output vector to the \textit{desired} output, given by the corresponding label associated with that training sample.
\paragraph*{}For example, in a Multilayer Perceptron Classifier with $k$ possible classes, the final output would be some vector, $\vec{x}^{(L-1)}$ of shape $k \times 1$. For some training sample with features $x^{(0)}$, belonging to class $\eta$, we can assemble a vector $\vec{y}$ of shape $k \times 1$ where all entries $y_i$ are $0$ except where $i = \eta$ the entries is given by a $1$. Thus we have the MLP Classifier output for a particular sample:
\begin{equation}
\label{MLP Output}
\vec{x}^{(L-1)} = \big[ x_0 , x_1 , ... , x_\eta , ... , 
x_{k-2} , x_{k-1} \big]^T
\end{equation}
And the target vector for that particular sample:
\begin{equation}
\label{MLP target}
\vec{y} = \big[ 0, 0 , ... , 1 , ... , 0 , 0 \big]^T
\end{equation}
\paragraph*{}With these two vectors, we can define some function $f$ that compute the \textit{error} or \textit{cost} of this particular sample. This function will measure how well or poorly the output of the MLP, (\ref{MLP Output}) compares to the target (\ref{MLP target}). This function can also be called the loss or objective function \cite{James}. The goal of any network to to use \textit{back propagration} to minimize the value of this objective function \cite{Geron}.

% ================================

\subsection{The Objective Function}
\paragraph*{}To determined how the network performed on this particular labeled sample, we define an objective function to minimize. Let the network be a classifier model with $k$ independent output classes. Thus the output layer has $n_{l-1} = k$ neurons in it. For this example, we use the \textit{means squared} error function \cite{James}. It is defined:
\begin{equation}
\label{MSE}
MSE = \frac{1}{k}\sum_{i=0}^{k-1} \Big( y_i - x^{(L-1)}_i \Big)^2
\end{equation}
Where $k$ is the number of possible output classes. 
\begin{itemize}

\item $y_i$ is the $i$-th element in the target vector as defined in equation (\ref{MLP target}), which is what this particular sample \textit{should} cause the output layer to look like. 
\item $x^{(L-1)}_i$ is the $i$-th element in the output vector defined in equation (\ref{MLP Output}) that is produced by the network for this particular sample. 
\end{itemize}
Both $\vec{x}^{(L-1)}$ and $\vec{y}$ are column vectors with $k$ elements.
\paragraph*{}If the vectors are indeed similar, then the MSE (\ref{MSE}) for that sample becomes quite small. If the network is still poorly trained, the output vector from the network may differ quite substantially from the target. Thus the element-wise difference squared will take on a very high value. Thus now, the task of training is to find the combination of weights and biases that minimize the objective function.

% ================================

\subsection{Gradient Descent}
\paragraph*{}The mean-squared objective function for a $k$-bins classifier at surface level only seems to be a dependent on the output vector $\vec{x}^{(L-1)}$ and the target vector $\vec{y}$. This would only make it dependent on 2 vectors of length $k$, thus only $2k$ parameters. However, it took a special combination of all elements in all weighting matrices, and each bias function to produce that value. When considering $L-1$ matrices, with $(n_{l-1} \times n_l)$ elements in each, and perhaps a unique bias function and activation function with each layer, it becomes apparent that the object function actually becomes dependent on a great many parameters.
\paragraph*{}For smaller networks with only a few internal layers, this may only amalgamate to a few hundred parameters to adjust \cite{Goodfellow}. In the case of larger and more complex \textit{deep learning models}, this may sum up to several ten or hundreds of thousands of parameters to adjust, making the task of minimization far more difficult. 
\paragraph*{}In traditional single variable calculus, to find the minimum of a function, $f(x)$, and find the places where it's first derivative is equal to zero: $\frac{df}{dx} = 0$. In the case of a multivariate problem, where $f$ is a scalar function of multiple variables, the problem is a little bit harder to solve, because it is very difficult to find where each partial derivative is equal to zero: $\frac{\partial f}{\partial x_1} = \frac{\partial f}{\partial x_2} = ... = 0$.
\paragraph*{}To attempt to find the minimum, we employ the stochastic gradient descent algorithm. Since our objective function, $f$ is not defined for every single set of inputs, we pseudo-randomly select a set of parameters - which is sometimes called \textit{cold start} \cite{Goodfellow}. These correspond to every single element in every single weighting matrix, along with every single bias function or other modifications made. Once a sample of training data is fed through the network, this pseudo-random set of parameters is likely to produce a poor result, and thus a large value for the objective function.

% ================================================================



% ================================================================

\begin{thebibliography}{9}
\bibliographystyle{apalike}

\bibitem{Geron}
Géron Aurélien. \textit{Hands-on Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems}. O'Reilly, 2017.

\bibitem{Goodfellow}
Goodfellow, Ian, et al.\textit{Deep Learning}. MIT Press, 2017.

\bibitem{James}
James, Gareth, et al. {An Introduction to Statistical Learning with Applications in R}. Springer, 2017.

\bibitem{McCulloch}
McCulloch, Warren S., and Walter Pitts. “A Logical Calculus of the Ideas Immanent in Nervous Activity.” \textit{The Bulletin of Mathematical Biophysics}, vol. 5, no. 4, 1943, pp. 115–133.

\bibitem{Petrik}
Petrik, Marek. “Introduction to Machine Learning.” Machine Learning. 22 Jan. 2020, Durham, New Hampshire.

\end{thebibliography}

% ================================================================

\end{document}